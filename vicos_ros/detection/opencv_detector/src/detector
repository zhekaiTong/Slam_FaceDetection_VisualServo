#!/usr/bin/env python
import roslib
roslib.load_manifest('opencv_detector')
import rospy
import sys, select, termios, tty
import time
import Image
import os
import cv2, numpy
#import cv2.cv as cv
from std_msgs.msg import String
from std_msgs.msg import Bool
import sensor_msgs.msg
from dynamic_reconfigure.server import Server as DynamicReconfigureServer
from detection_msgs.msg import Detection
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image

CV_WINDOW_TITLE = "OpenCV object detection"

# Node for object detection.
class Detector():

    def detect_objects(self, image, draw=False):
        min_size = (30,30)
        max_size = (60,60)
        haar_scale = 1.2
        min_neighbors = 3
        haar_flags = 0

        # Convert color input image to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        # Scale input image for faster processing
        if self.image_scale == None:
            self.image_scale = image.shape[1] / 240

        smallImage = cv2.resize(gray, (int(image.shape[1] / self.image_scale), int(image.shape[0] / self.image_scale)), interpolation=cv2.INTER_LINEAR)

        # Equalize the histogram
        smallImage = cv2.equalizeHist(smallImage)

        # Detect the objects
        results = self.detectorCascade.detectMultiScale(smallImage, haar_scale, min_neighbors, haar_flags, min_size, max_size)

        detections = []

        for (x, y, w, h) in results:
            pt1 = (int(x * self.image_scale), int(y * self.image_scale))
            pt2 = (int((x + w) * self.image_scale), int((y + h) * self.image_scale))

            if draw:
                cv2.rectangle(image, pt1, pt2, (255, 0, 0), 3, 8, 0)

            detection_image = image[pt1[1]:pt2[1], pt1[0]:pt2[0]]
            detections.append((pt1[0], pt1[1], pt2[0] - pt1[0], pt2[1] - pt1[1], numpy.copy(detection_image)))

        return detections

    def toggle_callback(self, data):
        self.enabled = data.data
        if self.enabled:
            rospy.loginfo("Object detection enabled")
        else:
            rospy.loginfo("Object detection disabled")
          
    def image_callback(self, data):
        if not self.enabled:
            return
        try:
            now = rospy.Time.now()
            if self.throttle and (now.to_sec() - self.throttle_time.to_sec()) < self.throttle:
                return

            self.throttle_time = now

            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
            detections = self.detect_objects(cv_image, self.cv_window)
	    predict_img = self.predict(cv_image)

            if len(detections) > 0:
 		print 'test detection'
                message = Detection()
                message.header.seq = self.message_counter
                message.header.stamp = data.header.stamp
                message.header.frame_id = data.header.frame_id
                for detection in detections:
                    message.x = detection[0]
                    message.y = detection[1]
                    message.width = detection[2]
                    message.height = detection[3]
                    message.source = 'opencv'
                    message.confidence = 1
                    message.image = self.bridge.cv2_to_imgmsg(detection[4], "bgr8")

		print message.x,'  ',message.y
                self.message_counter += 1
                self.detections_pub.publish(message)
            
            if self.cv_window:
                #cv2.imshow(CV_WINDOW_TITLE, cv_image)
		cv2.imshow(CV_WINDOW_TITLE, predict_img)
                cv2.waitKey(1)

        except CvBridgeError, e:
            print e
          
    def __init__(self):
	print("Preparing data...")
    	self.faces, self.labels = self.prepare_training_data("/home/zhekai/ELEC6910_ws/src/vicos_ros/detection/opencv_detector/training-data")
    	print("Data prepared")

    	#print total faces and labels
    	#print("Total faces: ", len(faces))
    	#print("Total labels: ", len(labels))

    	self.face_recognizer = cv2.face.LBPHFaceRecognizer_create()
	#self.face_recognizer = cv2.face.EigenFaceRecognizer_create()
    	self.face_recognizer.train(self.faces, numpy.array(self.labels))

        # Get the ~private namespace parameters from command line or launch file
        # Set basic paramateres
        self.image_scale = rospy.get_param('~scale', None)
        self.throttle = rospy.get_param('~throttle', 10)
        data_path = rospy.get_param('~detector_file', '')
        if not data_path:
            sys.exit(1)        

        self.throttle = None if self.throttle <= 0 else (1 / float(self.throttle))

        self.detectorCascade = cv2.CascadeClassifier(data_path)
        self.throttle_time = rospy.Time.now()

        # init camera capture stuff
        self.bridge = CvBridge()
        self.image_sub = rospy.Subscriber('camera', Image, self.image_callback, queue_size=1)

        # Subscribers and publishers
        self.detections_pub = rospy.Publisher('detections', Detection, queue_size=10)
        self.toggle_sub = rospy.Subscriber('toggle', Bool, self.toggle_callback, queue_size=10)

        # init and call detection
        self.enabled = rospy.get_param('~enabled', True)
        self.cv_window = rospy.get_param('~show_cv_window', False)
        self.message_counter = 0
	# face recognition
	self.subjects = ["Aubama", "Aiweier", "Zhangguorong", "jinling", "katong"]

    def detect_face(self, img):
        #convert the test image to gray image as opencv face detector expects gray images
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
        #load OpenCV face detector, I am using LBP which is fast
        #there is also a more accurate but slow Haar classifier
        face_cascade = cv2.CascadeClassifier('/home/zhekai/ELEC6910_ws/src/vicos_ros/detection/opencv_detector/data/haarcascade_face.xml')

        #let's detect multiscale (some images may be closer to camera than others) images
        #result is a list of faces
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);
    
        #if no faces are detected then return original img
        if (len(faces) == 0):
            return None, None
    
        #under the assumption that there will be only one face,
        #extract the face area
        (x, y, w, h) = faces[0]
    
        #return only the face part of the image
        return gray[y:y+w, x:x+h], faces[0]

    def prepare_training_data(self, data_folder_path):
    
        #------STEP-1--------
        #get the directories (one directory for each subject) in data folder
        dirs = os.listdir(data_folder_path)
    
        #list to hold all subject faces
        faces = []
        #list to hold labels for all subjects
        labels = []
    
        #let's go through each directory and read images within it
        for dir_name in dirs:
        
            #our subject directories start with letter 's' so
            #ignore any non-relevant directories if any
            if not dir_name.startswith("s"):
                continue;
            
            #------STEP-2--------
            #extract label number of subject from dir_name
            #format of dir name = slabel
            #, so removing letter 's' from dir_name will give us label
            label = int(dir_name.replace("s", ""))
	    print label
        
            #build path of directory containin images for current subject subject
            #sample subject_dir_path = "training-data/s1"
            subject_dir_path = data_folder_path + "/" + dir_name
        
            #get the images names that are inside the given subject directory
            subject_images_names = os.listdir(subject_dir_path)
            print subject_images_names
        
            #------STEP-3--------
            #go through each image name, read image, 
            #detect face and add face to list of faces
            for image_name in subject_images_names:
            
                #ignore system files like .DS_Store
                if image_name.startswith("."):
                    continue;
            
                #build image path
                #sample image path = training-data/s1/1.pgm
                image_path = subject_dir_path + "/" + image_name

                #read image
                image = cv2.imread(image_path)
            
                #display an image window to show the image 
                #cv2.imshow("Training on image...", cv2.resize(image, (400, 500)))
                #cv2.waitKey(100)
            
                #detect face
                face, rect = self.detect_face(image)
            
                #------STEP-4--------
                #for the purpose of this tutorial
                #we will ignore faces that are not detected
                if face is not None:
                    #add face to list of faces
                    faces.append(face)
                    #add label for this face
                    labels.append(label)
            
        #cv2.destroyAllWindows()
        #cv2.waitKey(1)
        #cv2.destroyAllWindows()
    
	return faces, labels

    

    def draw_rectangle(self, img, rect):
    	(x, y, w, h) = rect
	cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
    def draw_text(self, img, text, x, y):
	cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)
    def predict(self, test_img):
    	#make a copy of the image as we don't want to chang original image
    	img = test_img.copy()
    	#detect face from the image
    	face, rect = self.detect_face(img)
	if not face is None:

    	    #predict the image using our face recognizer 
    	    label, confidence = self.face_recognizer.predict(face)
    	    #get name of respective label returned by face recognizer
    	    label_text = self.subjects[label]
    
    	    #draw a rectangle around face detected
    	    self.draw_rectangle(img, rect)
    	    #draw name of predicted person
    	    self.draw_text(img, label_text, rect[0], rect[1]-5)
    
	return img

# Main function.    
if __name__ == '__main__':

        # Initialize the node and name it.
        rospy.init_node('opencv_detector')
        try:
            fd = Detector()
            rospy.spin()    
        except rospy.ROSInterruptException: pass
